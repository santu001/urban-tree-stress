{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sFB6zNX1Zm5"
      },
      "outputs": [],
      "source": [
        "# - Trains two independent RandomForest models (Vitality, Stress)\n",
        "# - Uses raw PlanetScope bands + original indices + 8 extra indices\n",
        "# - Generates feature importance, confusion matrix, and per-class performance graphs.\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        ")\n",
        "from joblib import dump, load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CONFIG --------------------\n",
        "DATA_PATH = r\"/content/Data_To_Train_3_vitality.xlsx\"\n",
        "RAW_BANDS = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\"]\n",
        "TARGET_VITALITY = \"VitalityCategory\"\n",
        "TARGET_STRESS   = \"StressCategory\"\n",
        "\n",
        "TEST_SIZE    = 0.2\n",
        "RANDOM_STATE = 42\n",
        "EPS = 1e-6\n",
        "\n",
        "TEXTURE_PATCH_COLS = {\n",
        "    \"NDVI\": \"NDVI_patch\",\n",
        "    \"B7\":   \"B7_patch\",\n",
        "    \"B8\":   \"B8_patch\",\n",
        "}\n",
        "\n",
        "MODEL_DIR = Path(\"model_artifacts_extended\")\n",
        "(MODEL_DIR / \"vitality\").mkdir(exist_ok=True, parents=True)\n",
        "(MODEL_DIR / \"stress\").mkdir(exist_ok=True, parents=True)"
      ],
      "metadata": {
        "id": "q9Hmnu-r2BPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- FEATURE ENGINEERING --------------------\n",
        "def _safe_div(numer, denom):\n",
        "    return numer / np.clip(denom, EPS, None)\n",
        "\n",
        "def build_indices_base(df_bands: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Original 8 indices.\"\"\"\n",
        "    B2 = df_bands[\"B2\"].astype(float)\n",
        "    B4 = df_bands[\"B4\"].astype(float)\n",
        "    B6 = df_bands[\"B6\"].astype(float)\n",
        "    B7 = df_bands[\"B7\"].astype(float)\n",
        "    B8 = df_bands[\"B8\"].astype(float)\n",
        "\n",
        "    NDVI = _safe_div(B8 - B6, B8 + B6)\n",
        "    EVI  = 2.5 * _safe_div(B8 - B6, (B8 + 6.0*B6 - 7.5*B2 + 1.0))\n",
        "    NDRE = _safe_div(B8 - B7, B8 + B7)\n",
        "    CIre = _safe_div(B8, B7) - 1.0\n",
        "    GNDVI = _safe_div(B8 - B4, B8 + B4)\n",
        "\n",
        "    ratio_RE_Red   = _safe_div(B7, B6)\n",
        "    ratio_Red_NIR  = _safe_div(B6, B8)\n",
        "    ratio_Blue_Red = _safe_div(B2, B6)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"NDVI\": NDVI, \"EVI\": EVI, \"NDRE\": NDRE, \"CIre\": CIre, \"GNDVI\": GNDVI,\n",
        "        \"ratio_RE_Red\": ratio_RE_Red, \"ratio_Red_NIR\": ratio_Red_NIR, \"ratio_Blue_Red\": ratio_Blue_Red,\n",
        "    })\n",
        "\n",
        "def build_indices_extra(df_bands: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Extra 8 indices.\"\"\"\n",
        "    B2 = df_bands[\"B2\"].astype(float)\n",
        "    B3 = df_bands[\"B3\"].astype(float)\n",
        "    B4 = df_bands[\"B4\"].astype(float)\n",
        "    B6 = df_bands[\"B6\"].astype(float)\n",
        "    B7 = df_bands[\"B7\"].astype(float)\n",
        "    B8 = df_bands[\"B8\"].astype(float)\n",
        "\n",
        "    SAVI = 1.5 * _safe_div(B8 - B6, B8 + B6 + 0.5)\n",
        "    MSAVI2 = 0.5 * (2.0*B8 + 1.0 - np.sqrt(np.clip((2.0*B8 + 1.0)**2 - 8.0*(B8 - B6), 0, None)))\n",
        "    RDVI = _safe_div(B8 - B6, np.sqrt(np.clip(B8 + B6, EPS, None)))\n",
        "    PRI = _safe_div(B3 - B4, B3 + B4)\n",
        "    VARI = _safe_div(B4 - B6, B4 + B6 - B2)\n",
        "    CIgreen = _safe_div(B8, B4) - 1.0\n",
        "    MTCI = _safe_div(B8 - B7, B7 - B6)\n",
        "    NDWI = _safe_div(B4 - B8, B4 + B8)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"SAVI\": SAVI, \"MSAVI2\": MSAVI2, \"RDVI\": RDVI, \"PRI\": PRI,\n",
        "        \"VARI\": VARI, \"CIgreen\": CIgreen, \"MTCI\": MTCI, \"NDWI\": NDWI,\n",
        "    })\n",
        "\n",
        "def build_texture_optional(df_source: pd.DataFrame, idx_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    avail_cols = [c for c in TEXTURE_PATCH_COLS.values() if c in df_source.columns]\n",
        "    if not avail_cols:\n",
        "        return pd.DataFrame(index=idx_df.index)\n",
        "\n",
        "    out = {}\n",
        "    for name, col in TEXTURE_PATCH_COLS.items():\n",
        "        if col not in df_source.columns:\n",
        "            continue\n",
        "        vals = df_source[col]\n",
        "        means, stds = [], []\n",
        "        for v in vals:\n",
        "            if isinstance(v, (list, tuple, np.ndarray)) and len(v) > 0:\n",
        "                arr = np.asarray(v, dtype=float)\n",
        "                means.append(np.nanmean(arr))\n",
        "                stds.append(np.nanstd(arr))\n",
        "            else:\n",
        "                means.append(np.nan)\n",
        "                stds.append(np.nan)\n",
        "        out[f\"tex_{name}_mean\"] = means\n",
        "        out[f\"tex_{name}_std\"]  = stds\n",
        "\n",
        "    tex_df = pd.DataFrame(out, index=idx_df.index)\n",
        "    if tex_df.isna().all().all():\n",
        "        return pd.DataFrame(index=idx_df.index)\n",
        "    return tex_df.fillna(tex_df.median(numeric_only=True))\n",
        "\n",
        "def make_feature_matrix(df_full: pd.DataFrame):\n",
        "    base_idx  = build_indices_base(df_full[RAW_BANDS])\n",
        "    extra_idx = build_indices_extra(df_full[RAW_BANDS])\n",
        "    tex_feats = build_texture_optional(df_full, base_idx)\n",
        "    X = pd.concat([df_full[RAW_BANDS].astype(float), base_idx, extra_idx, tex_feats], axis=1)\n",
        "    return X, list(base_idx.columns), list(extra_idx.columns), list(tex_feats.columns)"
      ],
      "metadata": {
        "id": "bvF8nK-41_Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- VISUALIZATION HELPERS --------------------\n",
        "def plot_confusion_matrix(cm, class_names, title, save_path):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f\"{title} - Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "def plot_class_report(report_dict, title, save_path):\n",
        "    df = pd.DataFrame(report_dict).T\n",
        "    df = df.drop([\"accuracy\"], errors=\"ignore\")\n",
        "    df = df.loc[~df.index.str.contains(\"avg\", case=False)]\n",
        "    df[[\"precision\", \"recall\", \"f1-score\"]].plot(kind=\"bar\", figsize=(7,5))\n",
        "    plt.title(f\"{title} - Per-Class Performance\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "def plot_feature_importance(model, feature_names, title, save_path, top_n=20):\n",
        "    imp = model.feature_importances_\n",
        "    order = np.argsort(imp)[::-1][:top_n]\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x=imp[order], y=[feature_names[i] for i in order], palette=\"mako\")\n",
        "    plt.title(f\"{title} - Top {top_n} Feature Importances\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "DcN7Di_G1670"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- LOAD DATA --------------------\n",
        "print(\"Loading data...\")\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "\n",
        "required = RAW_BANDS + [TARGET_VITALITY, TARGET_STRESS]\n",
        "missing = [c for c in required if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing columns in data: {missing}\")\n",
        "\n",
        "optional_cols = [c for c in TEXTURE_PATCH_COLS.values() if c in df.columns]\n",
        "df = df[required + optional_cols].copy()\n",
        "\n",
        "before = len(df)\n",
        "df = df.dropna(subset=RAW_BANDS + [TARGET_VITALITY, TARGET_STRESS]).reset_index(drop=True)\n",
        "after = len(df)\n",
        "print(f\"Rows before/after NA drop: {before}/{after}\")"
      ],
      "metadata": {
        "id": "S5_o_hck1yAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- FEATURES & TARGETS --------------------\n",
        "X, base_cols, extra_cols, tex_cols = make_feature_matrix(df)\n",
        "FEATURE_COLS = RAW_BANDS + base_cols + extra_cols + (tex_cols if tex_cols else [])\n",
        "print(f\"Total features: {X.shape[1]} (raw={len(RAW_BANDS)}, base={len(base_cols)}, extra={len(extra_cols)}, texture={len(tex_cols)})\")\n",
        "\n",
        "y_vital  = df[TARGET_VITALITY].astype(str)\n",
        "y_stress = df[TARGET_STRESS].astype(str)\n",
        "\n",
        "# -------------------- ENCODERS --------------------\n",
        "le_vital  = LabelEncoder().fit(y_vital)\n",
        "le_stress = LabelEncoder().fit(y_stress)\n",
        "yv = le_vital.transform(y_vital)\n",
        "ys = le_stress.transform(y_stress)\n",
        "\n",
        "print(\"Vitality classes:\", list(le_vital.classes_))\n",
        "print(\"Stress classes:\",   list(le_stress.classes_))\n"
      ],
      "metadata": {
        "id": "PgciiN4B10S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- SPLITS --------------------\n",
        "Xv_tr, Xv_te, yv_tr, yv_te = train_test_split(\n",
        "    X, yv, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=yv\n",
        ")\n",
        "Xs_tr, Xs_te, ys_tr, ys_te = train_test_split(\n",
        "    X, ys, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=ys\n",
        ")\n",
        "\n",
        "# -------------------- MODELS --------------------\n",
        "rf_params = dict(\n",
        "    n_estimators=500,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=2,\n",
        "    class_weight=\"balanced_subsample\",\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "rf_vital  = RandomForestClassifier(**rf_params)\n",
        "rf_stress = RandomForestClassifier(**rf_params)\n",
        "\n",
        "print(\"Training Vitality model...\")\n",
        "rf_vital.fit(Xv_tr, yv_tr)\n",
        "print(\"Training Stress model...\")\n",
        "rf_stress.fit(Xs_tr, ys_tr)"
      ],
      "metadata": {
        "id": "w7GjQP2B1p-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- EVALUATION --------------------\n",
        "def eval_target(X_te, y_te, y_hat, label_encoder, name, model, feature_cols):\n",
        "    acc   = (y_hat == y_te).mean()\n",
        "    bal   = balanced_accuracy_score(y_te, y_hat)\n",
        "    f1m   = f1_score(y_te, y_hat, average=\"macro\", zero_division=0)\n",
        "    rep_dict = classification_report(\n",
        "        y_te, y_hat,\n",
        "        labels=np.arange(len(label_encoder.classes_)),\n",
        "        target_names=label_encoder.classes_,\n",
        "        output_dict=True,\n",
        "        digits=4, zero_division=0\n",
        "    )\n",
        "    print(f\"\\n==== {name} ====\")\n",
        "    print(f\"Accuracy: {acc:.4f} | Balanced Acc: {bal:.4f} | Macro-F1: {f1m:.4f}\")\n",
        "    print(classification_report(\n",
        "        y_te, y_hat,\n",
        "        labels=np.arange(len(label_encoder.classes_)),\n",
        "        target_names=label_encoder.classes_,\n",
        "        digits=4, zero_division=0\n",
        "    ))\n",
        "\n",
        "    cm = confusion_matrix(y_te, y_hat, labels=np.arange(len(label_encoder.classes_)))\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(pd.DataFrame(cm, index=[f\"true_{c}\" for c in label_encoder.classes_],\n",
        "                          columns=[f\"pred_{c}\" for c in label_encoder.classes_]))\n",
        "\n",
        "    # --- Visualization ---\n",
        "    outdir = MODEL_DIR / name\n",
        "    outdir.mkdir(exist_ok=True, parents=True)\n",
        "    plot_confusion_matrix(cm, label_encoder.classes_, name, outdir / f\"{name}_confusion_matrix.png\")\n",
        "    plot_class_report(rep_dict, name, outdir / f\"{name}_class_report.png\")\n",
        "    plot_feature_importance(model, feature_cols, name, outdir / f\"{name}_feature_importance.png\")\n",
        "\n",
        "yv_hat = rf_vital.predict(Xv_te)\n",
        "ys_hat = rf_stress.predict(Xs_te)\n",
        "eval_target(Xv_te, yv_te, yv_hat, le_vital, \"VitalityCategory\", rf_vital, FEATURE_COLS)\n",
        "eval_target(Xs_te, ys_te, ys_hat, le_stress, \"StressCategory\", rf_stress, FEATURE_COLS)\n",
        "\n",
        "# -------------------- SAVE --------------------\n",
        "print(\"\\nSaving artifacts...\")\n",
        "dump(rf_vital, MODEL_DIR / \"vitality\" / \"rf_vitality_ext.joblib\")\n",
        "dump(le_vital, MODEL_DIR / \"vitality\" / \"label_encoder_vitality.joblib\")\n",
        "dump(rf_stress, MODEL_DIR / \"stress\" / \"rf_stress_ext.joblib\")\n",
        "dump(le_stress, MODEL_DIR / \"stress\" / \"label_encoder_stress.joblib\")\n",
        "\n",
        "print(f\"Artifacts saved to: {MODEL_DIR.resolve()}\")\n"
      ],
      "metadata": {
        "id": "TPeqm-vC1l38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}